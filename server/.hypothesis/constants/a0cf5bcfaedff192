# file: C:\Projects\DKH-RTS-Game-Nesus-Of-Mind\server\ai_engine\adaptive_difficulty.py
# hypothesis_version: 6.150.1

[-0.15, -0.1, -0.08, -0.05, 0.0, 0.005, 0.01, 0.02, 0.05, 0.08, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 20.0, 100.0, 300.0, 600.0, 100, 300, 'actual_success_rate', 'adaptation', 'adaptation_rate', 'adaptation_speed', 'adjustment_made', 'adjustment_reason', 'adjustment_signal', 'adjustment_too_small', 'boredom_level', 'combat_encounters', 'confidence', 'consistency', 'consistency_trend', 'cooldown_active', 'coordination_level', 'current_difficulty', 'current_phase', 'declining', 'difficulty', 'difficulty_level', 'dimensions', 'effectiveness', 'engagement', 'engagement_level', 'engagement_status', 'engagement_trend', 'error', 'factors', 'frustration_level', 'game_duration', 'general_adjustment', 'good', 'initial', 'is_plateaued', 'learning', 'learning_plateau', 'learning_progress', 'learning_rate', 'level', 'metrics', 'moderate', 'new_phase', 'new_target', 'none', 'optimal', 'pattern_recognition', 'performance_trends', 'phase_history', 'plateau', 'plateau_duration', 'player_bored', 'player_frustrated', 'player_metrics', 'player_skill_level', 'player_won', 'poor', 'predictive_ability', 'previous_phase', 'queens_killed', 'rapid_learning', 'reaction_speed', 'reason', 'recent_adjustments', 'resource_efficiency', 'resource_management', 'resources_gathered', 'sample_size', 'should_adjust', 'skill', 'skill_assessment', 'skill_declining', 'skill_improving', 'skill_level', 'skill_trend', 'status', 'steady_learning', 'strategic_decisions', 'strategic_thinking', 'strategy_complexity', 'success_rate', 'success_rate_too_low', 'success_rate_trend', 'survival_time', 'survival_time_trend', 'tactical_execution', 'target_difficulty', 'target_success_rate', 'timestamp', 'total_progress', 'units_created', 'unknown', 'won']