# file: C:\Projects\DKH-RTS-Game-Nesus-Of-Mind\server\ai_engine\neural_network.py
# hypothesis_version: 6.150.1

[-1.0, 0.0, 0.0001, 0.0005, 0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1.0, 10.0, 20.0, 50.0, 100.0, 300.0, 600.0, 1000.0, 120, 128, 500, 'GPU', 'GPU_MEMORY_LIMIT', 'accuracy', 'active_mining', 'aggression_score', 'assault_pattern', 'batch_size', 'combat_frequency', 'combat_intensity', 'complexity_level', 'convergence_achieved', 'coordinated_attack', 'coordination_level', 'death_cause', 'dense_hidden_1', 'dense_hidden_2', 'dense_input', 'dense_output', 'directness', 'dropout_hidden_1', 'dropout_input', 'economic_focus', 'energy_level', 'epochs_trained', 'error', 'expansion_rate', 'flanking_tendency', 'force_concentration', 'formation_preference', 'game_state', 'game_state_features', 'generation', 'gpu_used', 'hive_discovery_time', 'inf', 'learning_rate', 'loss', 'max_epochs', 'min_delta', 'min_learning_rate', 'mixed_float16', 'monitor', 'parasites_spawned', 'patience', 'performance_monitor', 'player_patterns', 'player_units', 'protector_assault', 'protectors', 'relu', 'resource_density', 'resource_efficiency', 'retreat_threshold', 'reward_signal', 'risk_tolerance', 'scouting_frequency', 'softmax', 'status', 'strategy_adaptation', 'strategy_labels', 'success', 'survival_time', 'training_config', 'training_time', 'training_type', 'unit_coordination', 'unknown', 'val_loss', 'worker_infiltration', 'workers']